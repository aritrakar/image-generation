{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GK9gmfL4KxeF"
      },
      "source": [
        "# Generative Adversarial Networks (GANs)\n",
        "\n",
        "In this project, I explore the implementation and training of Generative Adversarial Networks (GANs). GANs are a class of machine learning frameworks designed by Ian Goodfellow and his colleagues in 2014. They consist of two neural networks, the generator and the discriminator, which compete against each other to create realistic synthetic data.\n",
        "\n",
        "This project aims to implement a simple GAN and train it to generate images similar to those in the MNIST dataset. The MNIST dataset contains images of handwritten digits and is a common benchmark in the field of machine learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_n-Mg5YdE5YR"
      },
      "source": [
        "## Data Preparation\n",
        "\n",
        "The first step in our project is to prepare the data. We will use the MNIST dataset, which is a collection of 70,000 handwritten digits commonly used for training various image processing systems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "z-BU1m9IEXKY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "# Setting the device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "batch_size = 100\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "\n",
        "#ToDo: Build the train data loader using the above batch_size variable and shuffling the dataset.\n",
        "data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_-NwpdfFGQs"
      },
      "source": [
        "## Model Definition\n",
        "\n",
        "In this section, we define the architecture for our generator and discriminator networks. The generator takes random noise as input and generates images, while the discriminator attempts to distinguish between real and generated images. The Generator takes as input a Gaussian vector with dimension ```n_dim```. It consists of two linear layers with ```256``` and ```512``` nodes and the output layer should of dimension ```28*28=784``` so that it can be considered as unfolding a ```28*28``` image into a vector. The architecture of the generator and discriminators are kept simple for efficient training with limited resources - naturally, this sacrifices the quality of the generated images. The Discriminator takes as input an image of size ```28*28```. It consists of two linear layers with ```512``` and ```256``` nodes and the output layer is a single node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uACYmlwwG2tL"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, n_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.fc1 = nn.Linear(n_dim, 256)\n",
        "        self.fc2 = nn.Linear(256, 512)\n",
        "        self.fc3 = nn.Linear(512, 784)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = torch.tanh(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1) # Making sure that the batch of images has the shape [batch_size,28*28] instead of [batch_size,1,28,28]\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = torch.sigmoid(self.fc3(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXItGnRYK69p"
      },
      "source": [
        "## Training the GAN\n",
        "\n",
        "Next, we define the optimizers and loss function. Then, we train the GAN using a combination of the generator and discriminator losses. The generator aims to fool the discriminator by generating realistic images, while the discriminator aims to correctly identify real and generated images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RA8t-sCQZ8SG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf75fe18-d522-4c3a-c6a7-93595e8e8b28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Step [300/600], Discriminator Loss: 0.2444, Generator Loss: 4.3924, Real Score: 0.9120, Fake Score: 0.0144\n",
            "Epoch [1/100], Step [600/600], Discriminator Loss: 0.0818, Generator Loss: 4.6962, Real Score: 0.9859, Fake Score: 0.0124\n",
            "Epoch [2/100], Step [300/600], Discriminator Loss: 0.2217, Generator Loss: 3.3963, Real Score: 0.9178, Fake Score: 0.0429\n",
            "Epoch [2/100], Step [600/600], Discriminator Loss: 0.6254, Generator Loss: 2.2953, Real Score: 0.8808, Fake Score: 0.1212\n",
            "Epoch [3/100], Step [300/600], Discriminator Loss: 0.3794, Generator Loss: 2.7233, Real Score: 0.8643, Fake Score: 0.0734\n",
            "Epoch [3/100], Step [600/600], Discriminator Loss: 0.2377, Generator Loss: 3.8539, Real Score: 0.9403, Fake Score: 0.0319\n",
            "Epoch [4/100], Step [300/600], Discriminator Loss: 0.2314, Generator Loss: 3.1529, Real Score: 0.9334, Fake Score: 0.0971\n",
            "Epoch [4/100], Step [600/600], Discriminator Loss: 0.4365, Generator Loss: 4.3912, Real Score: 0.8302, Fake Score: 0.0396\n",
            "Epoch [5/100], Step [300/600], Discriminator Loss: 0.5554, Generator Loss: 3.9432, Real Score: 0.8199, Fake Score: 0.0603\n",
            "Epoch [5/100], Step [600/600], Discriminator Loss: 0.5021, Generator Loss: 2.8448, Real Score: 0.8196, Fake Score: 0.0770\n",
            "Epoch [6/100], Step [300/600], Discriminator Loss: 0.3312, Generator Loss: 3.7780, Real Score: 0.8902, Fake Score: 0.0453\n",
            "Epoch [6/100], Step [600/600], Discriminator Loss: 0.4524, Generator Loss: 3.1263, Real Score: 0.8881, Fake Score: 0.0764\n",
            "Epoch [7/100], Step [300/600], Discriminator Loss: 0.4399, Generator Loss: 2.6955, Real Score: 0.8895, Fake Score: 0.1341\n",
            "Epoch [7/100], Step [600/600], Discriminator Loss: 0.2639, Generator Loss: 3.8807, Real Score: 0.9496, Fake Score: 0.0504\n",
            "Epoch [8/100], Step [300/600], Discriminator Loss: 0.4787, Generator Loss: 3.1234, Real Score: 0.9334, Fake Score: 0.0976\n",
            "Epoch [8/100], Step [600/600], Discriminator Loss: 0.1684, Generator Loss: 4.0163, Real Score: 0.9620, Fake Score: 0.0451\n",
            "Epoch [9/100], Step [300/600], Discriminator Loss: 0.4669, Generator Loss: 5.2118, Real Score: 0.8520, Fake Score: 0.0279\n",
            "Epoch [9/100], Step [600/600], Discriminator Loss: 0.2735, Generator Loss: 4.8091, Real Score: 0.9005, Fake Score: 0.0195\n",
            "Epoch [10/100], Step [300/600], Discriminator Loss: 0.3381, Generator Loss: 3.3156, Real Score: 0.8849, Fake Score: 0.0745\n",
            "Epoch [10/100], Step [600/600], Discriminator Loss: 0.2223, Generator Loss: 3.9296, Real Score: 0.9374, Fake Score: 0.0430\n",
            "Epoch [11/100], Step [300/600], Discriminator Loss: 0.3709, Generator Loss: 4.2751, Real Score: 0.9048, Fake Score: 0.0492\n",
            "Epoch [11/100], Step [600/600], Discriminator Loss: 0.4237, Generator Loss: 3.6730, Real Score: 0.8532, Fake Score: 0.0436\n",
            "Epoch [12/100], Step [300/600], Discriminator Loss: 0.5097, Generator Loss: 3.4318, Real Score: 0.8003, Fake Score: 0.0728\n",
            "Epoch [12/100], Step [600/600], Discriminator Loss: 0.3447, Generator Loss: 3.3723, Real Score: 0.9059, Fake Score: 0.0770\n",
            "Epoch [13/100], Step [300/600], Discriminator Loss: 0.6994, Generator Loss: 3.0804, Real Score: 0.8931, Fake Score: 0.1039\n",
            "Epoch [13/100], Step [600/600], Discriminator Loss: 0.2715, Generator Loss: 3.0373, Real Score: 0.9269, Fake Score: 0.0831\n",
            "Epoch [14/100], Step [300/600], Discriminator Loss: 0.3800, Generator Loss: 3.3416, Real Score: 0.8600, Fake Score: 0.0590\n",
            "Epoch [14/100], Step [600/600], Discriminator Loss: 0.3388, Generator Loss: 3.2718, Real Score: 0.8723, Fake Score: 0.0676\n",
            "Epoch [15/100], Step [300/600], Discriminator Loss: 0.4279, Generator Loss: 3.0753, Real Score: 0.8998, Fake Score: 0.0785\n",
            "Epoch [15/100], Step [600/600], Discriminator Loss: 0.2872, Generator Loss: 4.0001, Real Score: 0.9281, Fake Score: 0.0325\n",
            "Epoch [16/100], Step [300/600], Discriminator Loss: 0.2450, Generator Loss: 4.4991, Real Score: 0.9230, Fake Score: 0.0244\n",
            "Epoch [16/100], Step [600/600], Discriminator Loss: 0.3090, Generator Loss: 4.2986, Real Score: 0.8978, Fake Score: 0.0266\n",
            "Epoch [17/100], Step [300/600], Discriminator Loss: 0.3785, Generator Loss: 3.0056, Real Score: 0.8877, Fake Score: 0.1101\n",
            "Epoch [17/100], Step [600/600], Discriminator Loss: 0.2023, Generator Loss: 3.7511, Real Score: 0.9598, Fake Score: 0.0533\n",
            "Epoch [18/100], Step [300/600], Discriminator Loss: 0.3201, Generator Loss: 4.1575, Real Score: 0.9146, Fake Score: 0.0660\n",
            "Epoch [18/100], Step [600/600], Discriminator Loss: 0.2118, Generator Loss: 2.8596, Real Score: 0.9316, Fake Score: 0.1036\n",
            "Epoch [19/100], Step [300/600], Discriminator Loss: 0.5558, Generator Loss: 2.9217, Real Score: 0.8448, Fake Score: 0.1285\n",
            "Epoch [19/100], Step [600/600], Discriminator Loss: 0.4375, Generator Loss: 3.2496, Real Score: 0.9621, Fake Score: 0.1059\n",
            "Epoch [20/100], Step [300/600], Discriminator Loss: 0.3186, Generator Loss: 4.1311, Real Score: 0.9117, Fake Score: 0.0455\n",
            "Epoch [20/100], Step [600/600], Discriminator Loss: 0.2929, Generator Loss: 3.2687, Real Score: 0.9306, Fake Score: 0.0922\n",
            "Epoch [21/100], Step [300/600], Discriminator Loss: 0.4906, Generator Loss: 3.4136, Real Score: 0.9010, Fake Score: 0.0882\n",
            "Epoch [21/100], Step [600/600], Discriminator Loss: 0.5067, Generator Loss: 3.8329, Real Score: 0.8292, Fake Score: 0.0535\n",
            "Epoch [22/100], Step [300/600], Discriminator Loss: 0.4924, Generator Loss: 3.5231, Real Score: 0.8822, Fake Score: 0.0664\n",
            "Epoch [22/100], Step [600/600], Discriminator Loss: 0.6018, Generator Loss: 2.8274, Real Score: 0.8640, Fake Score: 0.1663\n",
            "Epoch [23/100], Step [300/600], Discriminator Loss: 0.5125, Generator Loss: 2.6756, Real Score: 0.8102, Fake Score: 0.1164\n",
            "Epoch [23/100], Step [600/600], Discriminator Loss: 0.4636, Generator Loss: 4.4474, Real Score: 0.8291, Fake Score: 0.0314\n",
            "Epoch [24/100], Step [300/600], Discriminator Loss: 0.5546, Generator Loss: 2.9595, Real Score: 0.7850, Fake Score: 0.0993\n",
            "Epoch [24/100], Step [600/600], Discriminator Loss: 0.4352, Generator Loss: 2.9136, Real Score: 0.8074, Fake Score: 0.0918\n",
            "Epoch [25/100], Step [300/600], Discriminator Loss: 0.6594, Generator Loss: 2.3622, Real Score: 0.8886, Fake Score: 0.1536\n",
            "Epoch [25/100], Step [600/600], Discriminator Loss: 0.5308, Generator Loss: 2.9303, Real Score: 0.7962, Fake Score: 0.1224\n",
            "Epoch [26/100], Step [300/600], Discriminator Loss: 0.6759, Generator Loss: 3.0232, Real Score: 0.9400, Fake Score: 0.1015\n",
            "Epoch [26/100], Step [600/600], Discriminator Loss: 0.3924, Generator Loss: 4.7833, Real Score: 0.8670, Fake Score: 0.0307\n",
            "Epoch [27/100], Step [300/600], Discriminator Loss: 0.3855, Generator Loss: 3.3829, Real Score: 0.8550, Fake Score: 0.0838\n",
            "Epoch [27/100], Step [600/600], Discriminator Loss: 0.6817, Generator Loss: 2.4513, Real Score: 0.7929, Fake Score: 0.1629\n",
            "Epoch [28/100], Step [300/600], Discriminator Loss: 0.3926, Generator Loss: 2.9380, Real Score: 0.8595, Fake Score: 0.1073\n",
            "Epoch [28/100], Step [600/600], Discriminator Loss: 0.5547, Generator Loss: 2.2112, Real Score: 0.8904, Fake Score: 0.2327\n",
            "Epoch [29/100], Step [300/600], Discriminator Loss: 0.5189, Generator Loss: 3.7016, Real Score: 0.7901, Fake Score: 0.0662\n",
            "Epoch [29/100], Step [600/600], Discriminator Loss: 0.5374, Generator Loss: 2.9357, Real Score: 0.8826, Fake Score: 0.1175\n",
            "Epoch [30/100], Step [300/600], Discriminator Loss: 0.4758, Generator Loss: 2.7300, Real Score: 0.8928, Fake Score: 0.1474\n",
            "Epoch [30/100], Step [600/600], Discriminator Loss: 0.5470, Generator Loss: 3.4474, Real Score: 0.8239, Fake Score: 0.0845\n",
            "Epoch [31/100], Step [300/600], Discriminator Loss: 0.2102, Generator Loss: 3.7232, Real Score: 0.9630, Fake Score: 0.0567\n",
            "Epoch [31/100], Step [600/600], Discriminator Loss: 0.4737, Generator Loss: 2.4037, Real Score: 0.8135, Fake Score: 0.1504\n",
            "Epoch [32/100], Step [300/600], Discriminator Loss: 0.3216, Generator Loss: 3.7653, Real Score: 0.8550, Fake Score: 0.0634\n",
            "Epoch [32/100], Step [600/600], Discriminator Loss: 0.5153, Generator Loss: 3.7990, Real Score: 0.7900, Fake Score: 0.0630\n",
            "Epoch [33/100], Step [300/600], Discriminator Loss: 0.6284, Generator Loss: 3.3667, Real Score: 0.8072, Fake Score: 0.0925\n",
            "Epoch [33/100], Step [600/600], Discriminator Loss: 0.5503, Generator Loss: 2.6325, Real Score: 0.8483, Fake Score: 0.1424\n",
            "Epoch [34/100], Step [300/600], Discriminator Loss: 0.6624, Generator Loss: 2.6486, Real Score: 0.7817, Fake Score: 0.1427\n",
            "Epoch [34/100], Step [600/600], Discriminator Loss: 0.4030, Generator Loss: 2.3863, Real Score: 0.9077, Fake Score: 0.1559\n",
            "Epoch [35/100], Step [300/600], Discriminator Loss: 0.6635, Generator Loss: 2.3180, Real Score: 0.8389, Fake Score: 0.2086\n",
            "Epoch [35/100], Step [600/600], Discriminator Loss: 0.5135, Generator Loss: 2.1452, Real Score: 0.8857, Fake Score: 0.1860\n",
            "Epoch [36/100], Step [300/600], Discriminator Loss: 0.5020, Generator Loss: 2.6632, Real Score: 0.8280, Fake Score: 0.1320\n",
            "Epoch [36/100], Step [600/600], Discriminator Loss: 0.5314, Generator Loss: 2.3674, Real Score: 0.8588, Fake Score: 0.1940\n",
            "Epoch [37/100], Step [300/600], Discriminator Loss: 0.3552, Generator Loss: 2.9010, Real Score: 0.8775, Fake Score: 0.0983\n",
            "Epoch [37/100], Step [600/600], Discriminator Loss: 0.5507, Generator Loss: 2.8107, Real Score: 0.8369, Fake Score: 0.1234\n",
            "Epoch [38/100], Step [300/600], Discriminator Loss: 0.5465, Generator Loss: 2.3406, Real Score: 0.7910, Fake Score: 0.1471\n",
            "Epoch [38/100], Step [600/600], Discriminator Loss: 0.6514, Generator Loss: 3.0945, Real Score: 0.7600, Fake Score: 0.1032\n",
            "Epoch [39/100], Step [300/600], Discriminator Loss: 0.6012, Generator Loss: 3.1982, Real Score: 0.9128, Fake Score: 0.1003\n",
            "Epoch [39/100], Step [600/600], Discriminator Loss: 0.4253, Generator Loss: 3.1831, Real Score: 0.8646, Fake Score: 0.1093\n",
            "Epoch [40/100], Step [300/600], Discriminator Loss: 0.5135, Generator Loss: 3.5637, Real Score: 0.7903, Fake Score: 0.0666\n",
            "Epoch [40/100], Step [600/600], Discriminator Loss: 0.5805, Generator Loss: 2.6690, Real Score: 0.7886, Fake Score: 0.1267\n",
            "Epoch [41/100], Step [300/600], Discriminator Loss: 0.5615, Generator Loss: 3.7836, Real Score: 0.8050, Fake Score: 0.0608\n",
            "Epoch [41/100], Step [600/600], Discriminator Loss: 0.4074, Generator Loss: 3.2865, Real Score: 0.9062, Fake Score: 0.0997\n",
            "Epoch [42/100], Step [300/600], Discriminator Loss: 0.6690, Generator Loss: 1.9536, Real Score: 0.8600, Fake Score: 0.2279\n",
            "Epoch [42/100], Step [600/600], Discriminator Loss: 0.6164, Generator Loss: 2.4038, Real Score: 0.7555, Fake Score: 0.1557\n",
            "Epoch [43/100], Step [300/600], Discriminator Loss: 0.5323, Generator Loss: 3.0521, Real Score: 0.7503, Fake Score: 0.0839\n",
            "Epoch [43/100], Step [600/600], Discriminator Loss: 0.5368, Generator Loss: 2.8997, Real Score: 0.8181, Fake Score: 0.1109\n",
            "Epoch [44/100], Step [300/600], Discriminator Loss: 0.5106, Generator Loss: 2.4725, Real Score: 0.8527, Fake Score: 0.1526\n",
            "Epoch [44/100], Step [600/600], Discriminator Loss: 0.5246, Generator Loss: 2.7504, Real Score: 0.8117, Fake Score: 0.1132\n",
            "Epoch [45/100], Step [300/600], Discriminator Loss: 0.6240, Generator Loss: 2.7022, Real Score: 0.7457, Fake Score: 0.1094\n",
            "Epoch [45/100], Step [600/600], Discriminator Loss: 0.6184, Generator Loss: 3.0982, Real Score: 0.7752, Fake Score: 0.0864\n",
            "Epoch [46/100], Step [300/600], Discriminator Loss: 0.5641, Generator Loss: 2.0834, Real Score: 0.8295, Fake Score: 0.2005\n",
            "Epoch [46/100], Step [600/600], Discriminator Loss: 0.4811, Generator Loss: 2.4517, Real Score: 0.8578, Fake Score: 0.1344\n",
            "Epoch [47/100], Step [300/600], Discriminator Loss: 0.7493, Generator Loss: 2.2435, Real Score: 0.7360, Fake Score: 0.1827\n",
            "Epoch [47/100], Step [600/600], Discriminator Loss: 0.4730, Generator Loss: 2.2951, Real Score: 0.8076, Fake Score: 0.1339\n",
            "Epoch [48/100], Step [300/600], Discriminator Loss: 0.5278, Generator Loss: 2.6748, Real Score: 0.8084, Fake Score: 0.1208\n",
            "Epoch [48/100], Step [600/600], Discriminator Loss: 0.6931, Generator Loss: 2.1925, Real Score: 0.7932, Fake Score: 0.1668\n",
            "Epoch [49/100], Step [300/600], Discriminator Loss: 0.8740, Generator Loss: 2.1604, Real Score: 0.7768, Fake Score: 0.1879\n",
            "Epoch [49/100], Step [600/600], Discriminator Loss: 0.8186, Generator Loss: 1.8859, Real Score: 0.7748, Fake Score: 0.2404\n",
            "Epoch [50/100], Step [300/600], Discriminator Loss: 0.7472, Generator Loss: 2.1957, Real Score: 0.7575, Fake Score: 0.1644\n",
            "Epoch [50/100], Step [600/600], Discriminator Loss: 0.7209, Generator Loss: 1.6627, Real Score: 0.7823, Fake Score: 0.2538\n",
            "Epoch [51/100], Step [300/600], Discriminator Loss: 0.5431, Generator Loss: 2.2032, Real Score: 0.8217, Fake Score: 0.1790\n",
            "Epoch [51/100], Step [600/600], Discriminator Loss: 0.7666, Generator Loss: 2.2267, Real Score: 0.6732, Fake Score: 0.1654\n",
            "Epoch [52/100], Step [300/600], Discriminator Loss: 0.5339, Generator Loss: 2.2964, Real Score: 0.8265, Fake Score: 0.1596\n",
            "Epoch [52/100], Step [600/600], Discriminator Loss: 0.5873, Generator Loss: 2.3519, Real Score: 0.7974, Fake Score: 0.1727\n",
            "Epoch [53/100], Step [300/600], Discriminator Loss: 0.7117, Generator Loss: 2.0183, Real Score: 0.7761, Fake Score: 0.1972\n",
            "Epoch [53/100], Step [600/600], Discriminator Loss: 0.6083, Generator Loss: 2.2043, Real Score: 0.8666, Fake Score: 0.1916\n",
            "Epoch [54/100], Step [300/600], Discriminator Loss: 0.6696, Generator Loss: 2.1349, Real Score: 0.7750, Fake Score: 0.1753\n",
            "Epoch [54/100], Step [600/600], Discriminator Loss: 0.9040, Generator Loss: 1.9311, Real Score: 0.7836, Fake Score: 0.2363\n",
            "Epoch [55/100], Step [300/600], Discriminator Loss: 0.9803, Generator Loss: 1.8831, Real Score: 0.7230, Fake Score: 0.2236\n",
            "Epoch [55/100], Step [600/600], Discriminator Loss: 0.5292, Generator Loss: 2.4663, Real Score: 0.8119, Fake Score: 0.1510\n",
            "Epoch [56/100], Step [300/600], Discriminator Loss: 0.6074, Generator Loss: 1.7562, Real Score: 0.8218, Fake Score: 0.2471\n",
            "Epoch [56/100], Step [600/600], Discriminator Loss: 0.6391, Generator Loss: 1.8628, Real Score: 0.7777, Fake Score: 0.2210\n",
            "Epoch [57/100], Step [300/600], Discriminator Loss: 0.5581, Generator Loss: 2.0988, Real Score: 0.8067, Fake Score: 0.1850\n",
            "Epoch [57/100], Step [600/600], Discriminator Loss: 0.7411, Generator Loss: 1.8988, Real Score: 0.7219, Fake Score: 0.2022\n",
            "Epoch [58/100], Step [300/600], Discriminator Loss: 0.8533, Generator Loss: 1.4937, Real Score: 0.8148, Fake Score: 0.3084\n",
            "Epoch [58/100], Step [600/600], Discriminator Loss: 0.6020, Generator Loss: 1.9972, Real Score: 0.8053, Fake Score: 0.1990\n",
            "Epoch [59/100], Step [300/600], Discriminator Loss: 0.6442, Generator Loss: 2.0021, Real Score: 0.7713, Fake Score: 0.2130\n",
            "Epoch [59/100], Step [600/600], Discriminator Loss: 0.7110, Generator Loss: 2.1913, Real Score: 0.7257, Fake Score: 0.1855\n",
            "Epoch [60/100], Step [300/600], Discriminator Loss: 0.8851, Generator Loss: 2.7002, Real Score: 0.7631, Fake Score: 0.1344\n",
            "Epoch [60/100], Step [600/600], Discriminator Loss: 0.7771, Generator Loss: 2.0482, Real Score: 0.7622, Fake Score: 0.1925\n",
            "Epoch [61/100], Step [300/600], Discriminator Loss: 0.7530, Generator Loss: 1.7696, Real Score: 0.7579, Fake Score: 0.2403\n",
            "Epoch [61/100], Step [600/600], Discriminator Loss: 0.6930, Generator Loss: 1.8688, Real Score: 0.8386, Fake Score: 0.2430\n",
            "Epoch [62/100], Step [300/600], Discriminator Loss: 0.7309, Generator Loss: 1.9859, Real Score: 0.7002, Fake Score: 0.2189\n",
            "Epoch [62/100], Step [600/600], Discriminator Loss: 0.6791, Generator Loss: 2.0071, Real Score: 0.7888, Fake Score: 0.1900\n",
            "Epoch [63/100], Step [300/600], Discriminator Loss: 0.8625, Generator Loss: 2.1482, Real Score: 0.8048, Fake Score: 0.1939\n",
            "Epoch [63/100], Step [600/600], Discriminator Loss: 1.0507, Generator Loss: 1.7547, Real Score: 0.5878, Fake Score: 0.2352\n",
            "Epoch [64/100], Step [300/600], Discriminator Loss: 0.6516, Generator Loss: 1.6965, Real Score: 0.8069, Fake Score: 0.2532\n",
            "Epoch [64/100], Step [600/600], Discriminator Loss: 0.8801, Generator Loss: 1.8275, Real Score: 0.7394, Fake Score: 0.2561\n",
            "Epoch [65/100], Step [300/600], Discriminator Loss: 0.7924, Generator Loss: 1.7132, Real Score: 0.7678, Fake Score: 0.2787\n",
            "Epoch [65/100], Step [600/600], Discriminator Loss: 0.6918, Generator Loss: 2.1226, Real Score: 0.7584, Fake Score: 0.1813\n",
            "Epoch [66/100], Step [300/600], Discriminator Loss: 0.6635, Generator Loss: 2.0170, Real Score: 0.7641, Fake Score: 0.2016\n",
            "Epoch [66/100], Step [600/600], Discriminator Loss: 0.6947, Generator Loss: 1.8026, Real Score: 0.7933, Fake Score: 0.2240\n",
            "Epoch [67/100], Step [300/600], Discriminator Loss: 0.7649, Generator Loss: 1.6638, Real Score: 0.7895, Fake Score: 0.2731\n",
            "Epoch [67/100], Step [600/600], Discriminator Loss: 0.5305, Generator Loss: 2.0374, Real Score: 0.8393, Fake Score: 0.1802\n",
            "Epoch [68/100], Step [300/600], Discriminator Loss: 0.7269, Generator Loss: 1.8795, Real Score: 0.7502, Fake Score: 0.2118\n",
            "Epoch [68/100], Step [600/600], Discriminator Loss: 0.6565, Generator Loss: 1.9514, Real Score: 0.7651, Fake Score: 0.2081\n",
            "Epoch [69/100], Step [300/600], Discriminator Loss: 0.7425, Generator Loss: 1.8307, Real Score: 0.7758, Fake Score: 0.2272\n",
            "Epoch [69/100], Step [600/600], Discriminator Loss: 0.7761, Generator Loss: 1.5306, Real Score: 0.7593, Fake Score: 0.2887\n",
            "Epoch [70/100], Step [300/600], Discriminator Loss: 0.8234, Generator Loss: 1.9402, Real Score: 0.7421, Fake Score: 0.2146\n",
            "Epoch [70/100], Step [600/600], Discriminator Loss: 0.7591, Generator Loss: 1.4199, Real Score: 0.7721, Fake Score: 0.3102\n",
            "Epoch [71/100], Step [300/600], Discriminator Loss: 0.7586, Generator Loss: 1.7474, Real Score: 0.7383, Fake Score: 0.2317\n",
            "Epoch [71/100], Step [600/600], Discriminator Loss: 0.6847, Generator Loss: 1.8952, Real Score: 0.8271, Fake Score: 0.2317\n",
            "Epoch [72/100], Step [300/600], Discriminator Loss: 0.7447, Generator Loss: 1.3561, Real Score: 0.7822, Fake Score: 0.3263\n",
            "Epoch [72/100], Step [600/600], Discriminator Loss: 0.8611, Generator Loss: 1.3108, Real Score: 0.7737, Fake Score: 0.3529\n",
            "Epoch [73/100], Step [300/600], Discriminator Loss: 0.7465, Generator Loss: 1.8333, Real Score: 0.7062, Fake Score: 0.2238\n",
            "Epoch [73/100], Step [600/600], Discriminator Loss: 0.8337, Generator Loss: 1.8396, Real Score: 0.6907, Fake Score: 0.2121\n",
            "Epoch [74/100], Step [300/600], Discriminator Loss: 0.9589, Generator Loss: 1.7022, Real Score: 0.6829, Fake Score: 0.2676\n",
            "Epoch [74/100], Step [600/600], Discriminator Loss: 0.7073, Generator Loss: 2.1225, Real Score: 0.7368, Fake Score: 0.1858\n",
            "Epoch [75/100], Step [300/600], Discriminator Loss: 0.7057, Generator Loss: 2.2859, Real Score: 0.7347, Fake Score: 0.1536\n",
            "Epoch [75/100], Step [600/600], Discriminator Loss: 0.9968, Generator Loss: 1.5551, Real Score: 0.7081, Fake Score: 0.2907\n",
            "Epoch [76/100], Step [300/600], Discriminator Loss: 0.9090, Generator Loss: 1.5630, Real Score: 0.6890, Fake Score: 0.2689\n",
            "Epoch [76/100], Step [600/600], Discriminator Loss: 0.8271, Generator Loss: 1.8319, Real Score: 0.7618, Fake Score: 0.2426\n",
            "Epoch [77/100], Step [300/600], Discriminator Loss: 0.9967, Generator Loss: 1.2773, Real Score: 0.7364, Fake Score: 0.3541\n",
            "Epoch [77/100], Step [600/600], Discriminator Loss: 0.9669, Generator Loss: 1.4779, Real Score: 0.7566, Fake Score: 0.3081\n",
            "Epoch [78/100], Step [300/600], Discriminator Loss: 0.8972, Generator Loss: 1.4370, Real Score: 0.6812, Fake Score: 0.2939\n",
            "Epoch [78/100], Step [600/600], Discriminator Loss: 0.9219, Generator Loss: 1.4959, Real Score: 0.6526, Fake Score: 0.2822\n",
            "Epoch [79/100], Step [300/600], Discriminator Loss: 0.7365, Generator Loss: 1.9710, Real Score: 0.7313, Fake Score: 0.1984\n",
            "Epoch [79/100], Step [600/600], Discriminator Loss: 0.8375, Generator Loss: 1.4154, Real Score: 0.7275, Fake Score: 0.3191\n",
            "Epoch [80/100], Step [300/600], Discriminator Loss: 0.9587, Generator Loss: 1.5116, Real Score: 0.6566, Fake Score: 0.2989\n",
            "Epoch [80/100], Step [600/600], Discriminator Loss: 0.8324, Generator Loss: 1.7433, Real Score: 0.6648, Fake Score: 0.2338\n",
            "Epoch [81/100], Step [300/600], Discriminator Loss: 0.9656, Generator Loss: 1.5665, Real Score: 0.6987, Fake Score: 0.2886\n",
            "Epoch [81/100], Step [600/600], Discriminator Loss: 0.9745, Generator Loss: 2.0775, Real Score: 0.5868, Fake Score: 0.1910\n",
            "Epoch [82/100], Step [300/600], Discriminator Loss: 0.8593, Generator Loss: 1.4941, Real Score: 0.7470, Fake Score: 0.2957\n",
            "Epoch [82/100], Step [600/600], Discriminator Loss: 0.8451, Generator Loss: 1.7554, Real Score: 0.8062, Fake Score: 0.2649\n",
            "Epoch [83/100], Step [300/600], Discriminator Loss: 0.7773, Generator Loss: 1.8847, Real Score: 0.7048, Fake Score: 0.2096\n",
            "Epoch [83/100], Step [600/600], Discriminator Loss: 0.7411, Generator Loss: 1.6994, Real Score: 0.7931, Fake Score: 0.2618\n",
            "Epoch [84/100], Step [300/600], Discriminator Loss: 0.7861, Generator Loss: 1.7959, Real Score: 0.6794, Fake Score: 0.2101\n",
            "Epoch [84/100], Step [600/600], Discriminator Loss: 0.8704, Generator Loss: 1.7646, Real Score: 0.6801, Fake Score: 0.2542\n",
            "Epoch [85/100], Step [300/600], Discriminator Loss: 0.9026, Generator Loss: 1.8195, Real Score: 0.6319, Fake Score: 0.2183\n",
            "Epoch [85/100], Step [600/600], Discriminator Loss: 0.7985, Generator Loss: 1.3314, Real Score: 0.7276, Fake Score: 0.3185\n",
            "Epoch [86/100], Step [300/600], Discriminator Loss: 0.8500, Generator Loss: 1.4939, Real Score: 0.7481, Fake Score: 0.2914\n",
            "Epoch [86/100], Step [600/600], Discriminator Loss: 0.8388, Generator Loss: 1.5287, Real Score: 0.7811, Fake Score: 0.3034\n",
            "Epoch [87/100], Step [300/600], Discriminator Loss: 0.8621, Generator Loss: 1.8528, Real Score: 0.6950, Fake Score: 0.2118\n",
            "Epoch [87/100], Step [600/600], Discriminator Loss: 0.8701, Generator Loss: 1.4193, Real Score: 0.7049, Fake Score: 0.2823\n",
            "Epoch [88/100], Step [300/600], Discriminator Loss: 0.7151, Generator Loss: 1.7612, Real Score: 0.7409, Fake Score: 0.2354\n",
            "Epoch [88/100], Step [600/600], Discriminator Loss: 0.9675, Generator Loss: 1.5245, Real Score: 0.6364, Fake Score: 0.2679\n",
            "Epoch [89/100], Step [300/600], Discriminator Loss: 0.9628, Generator Loss: 1.3523, Real Score: 0.6770, Fake Score: 0.3182\n",
            "Epoch [89/100], Step [600/600], Discriminator Loss: 1.0676, Generator Loss: 1.8024, Real Score: 0.6088, Fake Score: 0.2492\n",
            "Epoch [90/100], Step [300/600], Discriminator Loss: 0.8863, Generator Loss: 1.3519, Real Score: 0.7037, Fake Score: 0.3155\n",
            "Epoch [90/100], Step [600/600], Discriminator Loss: 0.9610, Generator Loss: 1.2888, Real Score: 0.6968, Fake Score: 0.3384\n",
            "Epoch [91/100], Step [300/600], Discriminator Loss: 0.9096, Generator Loss: 1.6389, Real Score: 0.7422, Fake Score: 0.2687\n",
            "Epoch [91/100], Step [600/600], Discriminator Loss: 0.7674, Generator Loss: 1.6633, Real Score: 0.6857, Fake Score: 0.2390\n",
            "Epoch [92/100], Step [300/600], Discriminator Loss: 0.7231, Generator Loss: 1.9643, Real Score: 0.7491, Fake Score: 0.2022\n",
            "Epoch [92/100], Step [600/600], Discriminator Loss: 1.0918, Generator Loss: 1.2091, Real Score: 0.6784, Fake Score: 0.3751\n",
            "Epoch [93/100], Step [300/600], Discriminator Loss: 0.8076, Generator Loss: 1.4514, Real Score: 0.7617, Fake Score: 0.3238\n",
            "Epoch [93/100], Step [600/600], Discriminator Loss: 0.8117, Generator Loss: 1.6886, Real Score: 0.8379, Fake Score: 0.2710\n",
            "Epoch [94/100], Step [300/600], Discriminator Loss: 0.9471, Generator Loss: 1.5579, Real Score: 0.6130, Fake Score: 0.2601\n",
            "Epoch [94/100], Step [600/600], Discriminator Loss: 1.0099, Generator Loss: 1.4678, Real Score: 0.6928, Fake Score: 0.3108\n",
            "Epoch [95/100], Step [300/600], Discriminator Loss: 0.8045, Generator Loss: 1.3700, Real Score: 0.7452, Fake Score: 0.3100\n",
            "Epoch [95/100], Step [600/600], Discriminator Loss: 1.1000, Generator Loss: 1.5091, Real Score: 0.6020, Fake Score: 0.2956\n",
            "Epoch [96/100], Step [300/600], Discriminator Loss: 0.8613, Generator Loss: 1.7275, Real Score: 0.6737, Fake Score: 0.2400\n",
            "Epoch [96/100], Step [600/600], Discriminator Loss: 0.9401, Generator Loss: 1.6050, Real Score: 0.7258, Fake Score: 0.2809\n",
            "Epoch [97/100], Step [300/600], Discriminator Loss: 0.9964, Generator Loss: 1.3349, Real Score: 0.6527, Fake Score: 0.3336\n",
            "Epoch [97/100], Step [600/600], Discriminator Loss: 1.1451, Generator Loss: 1.3351, Real Score: 0.6408, Fake Score: 0.3419\n",
            "Epoch [98/100], Step [300/600], Discriminator Loss: 0.7458, Generator Loss: 1.7420, Real Score: 0.7701, Fake Score: 0.2543\n",
            "Epoch [98/100], Step [600/600], Discriminator Loss: 0.8646, Generator Loss: 1.6157, Real Score: 0.6525, Fake Score: 0.2511\n",
            "Epoch [99/100], Step [300/600], Discriminator Loss: 0.9794, Generator Loss: 1.7548, Real Score: 0.6340, Fake Score: 0.2421\n",
            "Epoch [99/100], Step [600/600], Discriminator Loss: 0.9420, Generator Loss: 1.3996, Real Score: 0.6689, Fake Score: 0.3264\n",
            "Epoch [100/100], Step [300/600], Discriminator Loss: 0.8760, Generator Loss: 1.7083, Real Score: 0.7921, Fake Score: 0.2513\n",
            "Epoch [100/100], Step [600/600], Discriminator Loss: 0.8617, Generator Loss: 1.5638, Real Score: 0.7602, Fake Score: 0.2927\n"
          ]
        }
      ],
      "source": [
        "n_dim = 100\n",
        "generator = Generator(n_dim).to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "lr = 0.0002\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr=lr)\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=lr)\n",
        "\n",
        "num_epochs = 100\n",
        "total_step = len(data_loader)\n",
        "real_scores = []\n",
        "fake_scores = []\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, _) in enumerate(data_loader):\n",
        "        real_images = images.to(device)\n",
        "\n",
        "        # Training discriminator\n",
        "        discriminator.zero_grad()\n",
        "\n",
        "        # Compute loss with real images\n",
        "        real_outputs = discriminator(real_images)\n",
        "        real_labels = torch.ones(real_images.size(0), 1).to(device)\n",
        "        d_loss_real = criterion(real_outputs, real_labels)\n",
        "\n",
        "        # Compute loss with fake images\n",
        "        noise = torch.randn(batch_size, n_dim).to(device)  # n_dim is the dimensionality of the input noise vector for the generator\n",
        "        fake_images = generator(noise)\n",
        "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "        fake_outputs = discriminator(fake_images.detach())  # Detach to avoid training generator on these labels\n",
        "        d_loss_fake = criterion(fake_outputs, fake_labels)\n",
        "\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "\n",
        "        # Training generator\n",
        "        generator.zero_grad()\n",
        "\n",
        "        #ToDo: compute g_loss\n",
        "        # Compute loss with fake images but flip labels to trick the discriminator\n",
        "        fake_outputs = discriminator(fake_images)  # No detach() here because we want to train the generator\n",
        "        target_labels = torch.ones(batch_size, 1).to(device)  # Try to fool the discriminator\n",
        "        g_loss = criterion(fake_outputs, target_labels)\n",
        "\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "        if (i+1) % 300 == 0:\n",
        "            # After updating the discriminator\n",
        "            real_score = torch.mean(real_outputs).item()\n",
        "            fake_score = torch.mean(fake_outputs.detach()).item()  # Use detach() to not affect gradients\n",
        "\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_step}], '\n",
        "                  f'Discriminator Loss: {d_loss.item():.4f}, Generator Loss: {g_loss.item():.4f}, '\n",
        "                  f'Real Score: {real_score:.4f}, Fake Score: {fake_score:.4f}')\n",
        "\n",
        "    # EXTRA\n",
        "    # Save the models\n",
        "    if (epoch % 10 == 0):\n",
        "        torch.save(generator.state_dict(), \"./etc/generator\")\n",
        "        torch.save(discriminator.state_dict(), \"./etc/discriminator\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3CGaQzDDRg8"
      },
      "source": [
        "## Results and Observations\n",
        "\n",
        "After training the GAN, we analyze the results by generating images and observing the training loss over epochs. The pictures do resemble handwritten digits as expected!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lvUJnaqSJCPM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "3a962a86-87eb-474e-cab6-dc900905b8d4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Generate 4 random noise vectors\n",
        "z = torch.randn(batch_size, n_dim).to(device)\n",
        "\n",
        "# Generate images\n",
        "with torch.no_grad():  # We don't need to track gradients here\n",
        "    generator.eval()  # Ensure the generator is in eval mode\n",
        "    fake_images = generator(z)\n",
        "\n",
        "# Assuming the generated images are 1x28x28 (for grayscale)\n",
        "# Adjust the code below if your image dimensions are different\n",
        "\n",
        "fig, axs = plt.subplots(2, 2, figsize=(6, 6))\n",
        "for i, ax in enumerate(axs.flat):\n",
        "    # The output from the generator will have the shape [Batch_size, Channels, Height, Width]\n",
        "    # Here we reshape it to [Height, Width] for matplotlib\n",
        "    img = fake_images[i].cpu().reshape(28, 28)  # Adjust for your dimensions\n",
        "    ax.imshow(img, cmap='gray')\n",
        "    ax.axis('off')  # Turn off axis numbering\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 user modules",
      "language": "python",
      "name": "python3-user-modules"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}